---
title: "TO404Proj1"
author: "Jack Zimmerman, Danielle Bidigare, Jeff Sondheimer, John McCarthy, Eliza Brown"
date: "11/22/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, cache = TRUE}
#Loading a pre-made sample csv file made from another RMD file that took a 5% sample of every data monthly dataset

citibike <- read.csv("citibike_sample_total.csv")
```

```{r}
str(citibike)

#Getting rid of the X variable as it is just a counter
citibike$X <- NULL


```

### Factorizing
```{r, cache = TRUE}

nrow(citibike[citibike$usertype == "Customer",])
#Setting all of the categorical variables to a factor
citibike$start.station.id <- as.factor(citibike$start.station.id)
citibike$start.station.name <- as.factor(citibike$start.station.name)

citibike$end.station.id <- as.factor(citibike$end.station.id)
citibike$end.station.name <- as.factor(citibike$end.station.name)

citibike$bikeid <- as.factor(citibike$bikeid)
citibike$usertype <- as.factor(citibike$usertype)

citibike$gender <- as.factor(citibike$gender)
#Give name to numeric gender classification
levels(citibike$gender)[levels(citibike$gender)=="0"] <- "Unknown"
levels(citibike$gender)[levels(citibike$gender)=="1"] <- "Male"
levels(citibike$gender)[levels(citibike$gender)=="2"] <- "Female"


#Creating an age column that will be easier to interpret
citibike$age <- 2019 - citibike$birth.year
head(citibike$age)

```
### Time and Data Cleaning
```{r}
library(tidyverse)


citibike$months <- months(as.Date(citibike$starttime))
citibike$months <- as.factor(citibike$months)

mode(citibike$months)
str(citibike$months)

citibike = citibike %>% mutate(date = substr(citibike$starttime, 1, 10) %>% parse_date(),
                               time = substr(citibike$starttime,12,19) %>% parse_time())

str(citibike$date)
str(citibike$time)

str(citibike)
```
```{r}
head(sort(citibike$age, decreasing = TRUE), 10)

#We don't know the reason why the age is wrong (they could have clicked on 1880 instead of 1980, but we can't justify this), so I am going to set the age of anyone over 90 to the mean of the sample

citibike$age <- ifelse(citibike$age >90, NA, citibike$age)
citibike$age <- ifelse(is.na(citibike$age) == TRUE, mean(citibike$age, na.rm = TRUE), citibike$age)

summary(citibike$age)

head(sort(citibike$tripduration, decreasing = TRUE), 10)
#All of these are likely "forgotten" and not returned. I wonder what the credit card bill looked like

filter(citibike, tripduration >1000000)

round(nrow(citibike %>%
  filter( tripduration > 60*24*7 & usertype == "Customer") %>%
  select(c(tripduration, usertype)))  / 
  nrow(citibike %>%
  filter( tripduration > 60*24*7) %>%
  select(c(tripduration, usertype)))*100, digits = 2)
```
### Distance Between Stations
```{r}
#Load geosphere so we can use distHaversine function
library(geosphere)
#Seeing if we can select the latitude and longtiude rows for the start column
head(select(citibike,c(start.station.latitude, start.station.longitude)))


citibike$distance <- distHaversine(select(citibike,c(start.station.latitude, start.station.longitude)),select(citibike, c(end.station.latitude, end.station.longitude)))

head(citibike$distance)

str(citibike)
```


#Data Exploration
```{r}
str(citibike)
avergae_trip_duration <- mean(citibike$tripduration)
median_trip_duration <- median(citibike$tripduration)
shortest_trip <- min(citibike$tripduration, na.rm=TRUE)
longest_trip <- max(citibike$tripduration, na.rm=TRUE)
```

##The longest trip is `r longest_trip` seconds, and the shortest trip is `r shortest_trip` seconds.

#Seeing how many "forgotten" bike trips there are. It's unlikely that anyone would have a bike greater than a week, so that's the criteria we'll use for a forgotten bike

```{r}
forgotten_bikes <- nrow(citibike[citibike$tripduration > 60*24*7,])
forgotten_bikes
```

##See what percent of forgotten bikes are from customers. 
```{r}
round(nrow(citibike %>%
  filter( tripduration > 60*24*7 & usertype == "Customer") %>%
  select(c(tripduration, usertype)))  / 
  nrow(citibike %>%
  filter( tripduration > 60*24*7) %>%
  select(c(tripduration, usertype)))*100, digits = 2)
```

##We have `r forgotten_bikes` bike trips in our data sample.

```{r}
total_number_user <- nrow(citibike[citibike$usertype,])
total_number_user

number_customer <- nrow(citibike[citibike$usertype=="Customer",])
number_subscriber <- nrow(citibike[citibike$usertype=="Subscriber",])
number_customer/total_number_user
number_subscriber/total_number_user
```

```{r}
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

getmode(citibike$start.station.name)
#This is right next to the Chrysler building in Manhattan, so Pershing Square makes sense as the most popular start station

#Getting number of trips started at Pershing Square North
nrow(citibike[citibike$start.station.name == "Pershing Square North",])


#Most popular end station. I'm curious to see if Pershing Square is also the most popular end destination
getmode(citibike$end.station.name)
#and it is the most popular


#Representative share of most popular station

#Expected number of trips per station with an equal distribution
nrow(citibike)/length(levels(citibike$start.station.name))

#Pershing Square trips as a percentage of expected number of trips

nrow(citibike[citibike$start.station.name == "Pershing Square North",])/(nrow(citibike)/length(levels(citibike$start.station.name)))
#There is a 7x increase in the expected number of trips

```

##More data exploration
```{r}
#Avg trip duration by user
avg_tripduration_by_user <- round(tapply(citibike$tripduration,citibike$usertype,mean,na.rm=TRUE),2)
avg_tripduration_by_user
tripduration_baseplot <- ggplot(data=citibike,aes(x=usertype,y=tripduration))
tripduration_baseplot+geom_boxplot(outlier.colour="black",outlier.shape=16,outlier.size=2,notch=TRUE)+coord_cartesian(ylim=c(0,2500))


```
```{r}

#density of user types by trip duration
ggplot(data = subset(citibike, tripduration<24*60), aes(x=tripduration, fill=usertype)) + geom_density(alpha=.5)

```

```{r}
#density of usertype by time

citibike = citibike %>% mutate(date = substr(citibike$starttime, 1, 10) %>% parse_date(),
                               time = substr(citibike$starttime,12,19) %>% parse_time())


ggplot(data = citibike, aes(x = time, fill = usertype)) + geom_density(alpha=.5) + scale_fill_discrete("User Type")

#stats for subscribers trip duration at 6AM to 9AM and 4PM to 7PM (ie rush hour times)
citibike %>% filter(time>parse_time("6:00:00") & time<parse_time("9:00:00") & usertype == "Subscriber") %>% select(tripduration) %>% summary()

citibike %>% filter(time>parse_time("16:00:00") & time<parse_time("19:00:00") & usertype == "Subscriber") %>% select(tripduration) %>% summary()


citibike %>% group_by(date) %>% count()

```



```{r}
str(citibike$months)
citibike$months <- as.factor(citibike$months)

citibike$months <- factor(citibike$months, levels = c("January","February", "March","April", "May", "June", "July", "August", "September", "October", "November", "December"))


ggplot(data = citibike, aes(x= months, fill = gender)) + geom_bar() + labs(title = "Number of Trips by Month", x = "Month", y = "Number of Trips")

ggplot(data = citibike, aes(x= months, fill = usertype)) + geom_bar() + labs(title = "Number of Trips by Month", x = "Month", y = "Number of Trips") +theme(axis.text.x = element_text(angle = 90))
```

# Temperature Effects

## Temp Data Cleaning
```{r}
tempdata <- read.csv("NYCWeather2019.csv")

str(tempdata)
summary(tempdata)

table(tempdata$STATION)
#All the same station, so we will get rid of this information. This station is located in Central Park, which is a great central point and fairly representative of the entire city
tempdata$STATION <- NULL
tempdata$NAME <- NULL


summary(tempdata$TAVG)
#Conventional average temperature is calculated by summing the maximum and minimum temperatures and dividing by two. That's what will be done for TAVG here
tempdata$TAVG <- (tempdata$TMIN + tempdata$TMAX)/2


#Doing some basic searches, AWND means average daily wind speed in meters per second, and SNWD means snow depth in millimeters. Snow depth implies how much snow is actively on the ground whereas snow implies how much fell from the sky (melting impacts and residual snow from days before)

#For the one NA in snow, it's fair to assume that it didn't snow that day.
tempdata$SNOW <- ifelse(is.na(tempdata$SNOW) == TRUE, 0, tempdata$SNOW)



#For AWND, we don't have the wind data from January 1st to March 9th, so we will replace all the NA's with the December mean. We chose just the December mean because weather doesn't really change until mid to late March anyways.

tempdata$AWND <- ifelse(is.na(tempdata$AWND) == TRUE, mean(tempdata$AWND[336:365]), tempdata$AWND)

head(tempdata$AWND, 30)
#The wind data for the first two months will be fairly inaccurate considering there is no variation, but we will live with this for now. We could potentially take the wind data from the next nearest weather station if it becomes inhibitory towards the analysis.
```
## Data Frame Merge
```{r}
summary(citibike$date)
summary(tempdata$DATE)
str(tempdata$DATE)

tempdata$DATE <- as.Date(tempdata$DATE, format = "%m/%d/%Y")
citibike <- merge(citibike, tempdata, by.x = "date", by.y = "DATE")
str(citibike)
```
## Data Exploration

```{r}

#can't set to variable
#How to count number of trips and overlay avg temp
#Avg temp and trip duration
#Wind and trip duration


avg_month_temp <- citibike %>% group_by(months) %>% summarise(mean(TAVG), mean(TMIN), mean(TMAX),count = n())
avg_month_temp <- avg_month_temp %>% rename(tavg = "mean(TAVG)",
                                            tmin = "mean(TMIN)",
                                            tmax = "mean(TMAX)")
avg_month_temp



ggplot(data = avg_month_temp, aes(x = months, y = tavg)) +geom_point() + geom_pointrange(aes(ymax = tmax, ymin = tmin)) +theme(axis.text.x = element_text(angle = 90))

#(data = avg_month_temp, aes(x = months)) + geom_bar(stat = "identity", aes(y = count)) + geom_pointrange(aes(y = tavg, ymax = tmax, ymin = tmin)) + scale_y_continuous(name = "Number of Rides", sec.axis = sec_axis(trans = ~10, name = "Average Temperature (F)"))



str(citibike)
```

## Trip Duration

```{r}
day_weather_data <- citibike %>% group_by(date) %>% summarize(mean(TAVG), mean(AWND), mean(SNOW), mean(SNWD), mean(tripduration), count = n())

day_weather_data <- day_weather_data %>% rename(tavg = "mean(TAVG)",
                                          tripduration = "mean(tripduration)",
                                          awnd  = "mean(AWND)",
                                          snow = "mean(SNOW)",
                                          snow_depth = "mean(SNWD)")

day_weather_data

ggplot(data = day_weather_data,aes(x = tavg, y = count)) + geom_point() + geom_smooth()
```



```{r}

ggplot(data = day_weather_data,aes(x = awnd, y = count)) + geom_point(aes(colour = (tavg < 35))) + geom_smooth()

ggplot(data = day_weather_data,aes(x = awnd, y = tripduration)) + geom_point(aes(colour = (tavg < 35))) + geom_smooth()
#Affects numbers of trips, windspeed above 6, a lot less "long distance" rides
```



```{r}
#Filtering out for the days in which it snowed in NYC
citibike %>% group_by(date) %>% filter(SNOW >0) %>% summarize(count = n(), mean(TAVG), mean(tripduration))
#Looks like it snowed 14 days in NYC


ggplot(data = day_weather_data, aes(x = tavg, y = count, colour = (snow > 0))) + geom_point()
ggplot(data = day_weather_data, aes(x = date, y = tavg, colour = (snow_depth > 0))) + geom_point()
ggplot(data = day_weather_data, aes(x = date, y = tripduration, colour = (snow > 0))) + geom_point()

```



